# description : "Tensors and Dynamic neural networks in Python with strong GPU acceleration"
# depends : google-glog gflags opencv openmp nccl pybind11 python python-yaml libuv

pkgbase=python-pytorch
name="python-pytorch" "python-pytorch-opt" "python-pytorch-cuda" "python-pytorch-opt-cuda"
_name="pytorch"
version=1.7.1
_version=1.7.1
release=4
url="https://pytorch.org"
         python-numpy protobuf ffmpeg python-future qt5-base onednn intel-mkl
make# depends : python python-setuptools python-yaml python-numpy cmake cuda
             cudnn git magma ninja pkgconfig doxygen
source="${_name}-${version}::git+https://github.com/pytorch/pytorch.git#tag=v$_version"
        fix_include_system.patch
        use-system-libuv.patch
        use-system-libuv2.patch
        nccl_version.patch
        disable_non_x86_64.patch
sha256sums=SKIP
            83c81ec6a461110da6ae6182529f58100986b068c5182ca62cd53c648b4e4fb0
            26b1dd596f1e21a011ee18cab939924483d6c6d4d98e543bf76f5a9312d54d67
            7b65c3b209fc39f92ba58a58be6d3da40799f1922910b1171ccd9209eda1f9eb
            e4a96887b41cbdfd4204ce5f16fcb16a23558d23126331794ab6aa30a66f2e0d
            d3ef8491718ed7e814fe63e81df2f49862fffbea891d2babbcb464796a1bd680

prepare {
   cd "${_name}-${version}"

  # This is the lazy way since pytorch has sooo many submodules and they keep
  # changing them around but weve run into more problems so far doing it the
  # manual than the lazy way. This lazy way not explicitly specifying all
  # submodules will make build()ing inefficient but for now Ill take it.
  # It will result in the same package, dont worry.
  git submodule update --init --recursive

  # https://bugs.archlinux.org/task/64981
  patch -N torch/utils/cpp_extension.py "${srcdir}"/fix_include_system.patch

  # Use system libuv
  patch -Np1 -i "${srcdir}"/use-system-libuv.patch

  # FindNCCL patch to export correct nccl version
  # patch -Np1 -i "${srcdir}"/nccl_version.patch

  # remove local nccl
  rm -rf third_party/nccl/nccl

   cd ..

  cp -a "${_name}-${version}" "${_name}-${version}-opt"
  cp -a "${_name}-${version}" "${_name}-${version}-cuda"
  cp -a "${_name}-${version}" "${_name}-${version}-opt-cuda"

  export VERBOSE=1
  export PYTORCH_BUILD_VERSION="${version}"
  export PYTORCH_BUILD_NUMBER=1

  # Check tools/setup_helpers/cmake.py, setup.py and CMakeLists.txt for a list of flags that can be set via env vars.
  export USE_MKLDNN=ON
  export BUILD_CUSTOM_PROTOBUF=OFF
  # export BUILD_SHARED_LIBS=OFF
  export USE_FFMPEG=ON
  export USE_GFLAGS=ON
  export USE_GLOG=ON
  export BUILD_BINARY=ON
  export USE_OPENCV=ON
  export USE_SYSTEM_NCCL=ON
  # export USE_SYSTEM_LIBS=ON
  export NCCL_VERSION=$pkg-config nccl --modversion
  export NCCL_VER_CODE=$sed -n s/^#define NCCL_VERSION_CODE\s*\.*\.*/\1/p /usr/include/nccl.h
  export CUDAHOSTCXX=g++
  export CUDA_HOME=/opt/cuda
  export CUDNN_LIB_DIR=/usr/lib
  export CUDNN_INCLUDE_DIR=/usr/include
  # export TORCH_NVCC_FLAGS="-Xfatbin -compress-all"
  export TORCH_CUDA_ARCH_LIST="5.2;5.3;6.0;6.1;6.2;7.0;7.0+PTX;7.2;7.2+PTX;7.5;7.5+PTX;8.0;8.0+PTX;8.6;8.6+PTX"
}

build()-delete {
  echo "Building without cuda and without non-x86-64 optimizations"
  export USE_CUDA=0
  export USE_CUDNN=0
   cd "${srcdir}/${_name}-${version}"
  patch -Np1 -i "${srcdir}/disable_non_x86_64.patch"
  python setup.py build


  echo "Building without cuda and with non-x86-64 optimizations"
  export USE_CUDA=0
  export USE_CUDNN=0
   cd "${srcdir}/${_name}-${version}-opt"
  python setup.py build


  echo "Building with cuda and without non-x86-64 optimizations"
  export USE_CUDA=1
  export USE_CUDNN=1
   cd "${srcdir}/${_name}-${version}-cuda"
  patch -Np1 -i "${srcdir}/disable_non_x86_64.patch"
  python setup.py build


  echo "Building with cuda and with non-x86-64 optimizations"
  export USE_CUDA=1
  export USE_CUDNN=1
   cd "${srcdir}/${_name}-${version}-opt-cuda"
  python setup.py build
}

_options="!checksum"

build() {
  # Prevent setup.py from re-running CMake and rebuild()ing
  sed -e s/RUN_BUILD_DEPS = True/RUN_BUILD_DEPS = False/g -i setup.py

  python setup.py build
  python setup.py install--root=$PKG / --optimize=1 


  pytorchpath="usr/lib/python3.9/site-packages/torch"
  install -d "${PKG}/usr/lib"

  # put CMake files in correct place
  mv "${PKG}/${pytorchpath}/share/cmake" "${PKG}/usr/lib/cmake"

  # put C++ API in correct place
  mv "${PKG}/${pytorchpath}/include" "${PKG}/usr/include"
  mv "${PKG}/${pytorchpath}/lib"/*.so* "${PKG}/usr/lib/"

  # clean up duplicates
  # TODO: move towards direct shared library dependecy of:
  #   c10, caffe2, libcpuinfo, CUDA RT, gloo, GTest, Intel MKL,
  #   NVRTC, ONNX, protobuf, libthreadpool, QNNPACK
  rm -rf "${PKG}/usr/include/pybind11"

  # python module is hardcoded to look there at runtime
  ln -s /usr/include "${PKG}/${pytorchpath}/include"
  find "${PKG}"/usr/lib -type f -name "*.so*" -print0 | while read -rd $\0 _lib; do
    ln -s ${_lib#$PKG} "${PKG}/${pytorchpath}/lib/"
  done
}

package_python-pytorch {
   cd "${srcdir}/${_name}-${version}"
  _package
}

package_python-pytorch-opt {
  # description : "Tensors and Dynamic neural networks in Python with strong GPU acceleration with AVX2 CPU optimizations"
  conflicts=python-pytorch
  provides=python-pytorch

   cd "${srcdir}/${_name}-${version}-opt"
  _package
}

package_python-pytorch-cuda {
  # description : "Tensors and Dynamic neural networks in Python with strong GPU acceleration with CUDA"
  depends+=cuda cudnn magma
  conflicts=python-pytorch
  provides=python-pytorch

   cd "${srcdir}/${_name}-${version}-cuda"
  _package
}

package_python-pytorch-opt-cuda {
  # description : "Tensors and Dynamic neural networks in Python with strong GPU acceleration with CUDA and AVX2 CPU optimizations"
  depends+=cuda cudnn magma
  conflicts=python-pytorch
  provides=python-pytorch python-pytorch-cuda

   cd "${srcdir}/${_name}-${version}-opt-cuda"
  _package
}

